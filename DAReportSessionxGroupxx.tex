%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% University/School Laboratory Report
% LaTeX Template
% Version 4.0 (March 21, 2022)
%
% This template originates from:
% https://www.LaTeXTemplates.com
%
% Authors:
% Vel (vel@latextemplates.com)
% Linux and Unix Users Group at Virginia Tech Wiki
%
% License:
% CC BY-NC-SA 4.0 (https://creativecommons.org/licenses/by-nc-sa/4.0/)
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%----------------------------------------------------------------------------------------
%	PACKAGES AND DOCUMENT CONFIGURATIONS
%----------------------------------------------------------------------------------------

\documentclass[
	article, % Paper size, specify a4paper (A4) or letterpaper (US letter)
	11pt, % Default font size, specify 10pt, 11pt or 12pt
]{CSUniSchoolLabReport}


\addbibresource{reference.bib} % Bibliography file (located in the same folder as the template)

\usepackage{enumitem}
\usepackage{hyperref}

%----------------------------------------------------------------------------------------
%	REPORT INFORMATION
%----------------------------------------------------------------------------------------

\title{CSC3105 Data Analytics Assignment} % Report title

\author{
        Woon Jun Wei \textit{2200624} \\
        Benjamin Loh Choon How \textit{2201590} \\
        Low Hong Sheng Jovian \textit{2203654}\\
        Wang Rongqi Richie \textit{2201942} \\
        Poon Xiang Yuan \textit{2200559} \\
    }

\date{\today} % Date of the report

%----------------------------------------------------------------------------------------

\begin{document}

\maketitle % Insert the title, author and date using the information specified above



% START of Jovian's draft for JW's verdict ): %
% DON TOUCH HERE unless u want to add on stuff %
\section{Background}\label{background}

\subsection{Emergence of IoT and Indoor Positioning Needs}\label{Emergence of IoT and Indoor Positioning Needs}
The advent of the Internet of Things (IoT) has revolutionized how we interact with our environment, giving rise to an increased demand for precise Indoor Positioning Systems (IPS). Applications range from pedestrian tracking to autonomous drones in logistics and social distancing protocols, all requiring reliable localization technologies.

\subsection{Limitations of GNSS in Indoor Environments}\label{Limitations of GNSS in Indoor Environments}
While the Global Navigation Satelite System (GNSS) has been a cornerstone for ourdoor localization, its effectiveness is drastically reduced indoors due to signal attentuation by obstacles like walls, making it unsuitable for indoor use.

\subsection{The Promise of UWB Technology}\label{The Promise of UWB Technology}
Ultra-Wideband (UWB) technology, with its short pulse duration, offers high temporal resolution, enabling high accuracy in IPS. Nonetheless, the accuracy of Ultra-wideband (UWB) systems is compromised under Non-Line-Of-Sight (NLOS) conditions, where signal obstructions or reflections occur, presenting a substantial hurdle due to the resulting deterioration in localization precision.

\subsection{Current NLOS Identification Methods}\label{Current NLOS Identification Methods}
The academic and industrial sectors have explored numerous methodologies to mitigate the NLOS issue in UWB systems. These range from non-feature-based approaches, leveraging contextual information, to feature-based methods that extract distinct waveform characteristics to identify NLOS conditions using maching learning (ML) techniques.

\subsection{Challenges and Limitations}\label{Challenges and Limitations}
Although ML has emerged as a promising solution for NLOS identification, existing feature-based approaches face challenges, particularly with imbalanced datasets where NLOS samples are scarce. This affects the robustness of the classifiers being trained.

\section{Introduction to the Project}\label{Introduction to the Project}
Against this backdrop, our project aims to address the critical challenge of distinguishing between LOS and NLOS conditions in UWB-based IPS. We intend to train a machine learning model using the given dataset, with the ultimate goal of enhancing UWB localization accuracy irrespective of LOS or NLOS conditions. Acknowledging the limitations of traditional ML approaches in handling imbalanced data, we will explore a three-dimensional-process-centric approach over sheer accuracy metrics. This strategy focuses on developing a robust classifier that remains effective even with limited NLOS data, a common scenario in real-world applications.


% og intro, if above ok can combine / remove %
\section{Introduction}\label{introduction}
In the realm of signal processing and analytics, a diverse array of operations is available for data preprocessing, model training (data mining), and visualization. Notably, signal data acquired from Ultra-Wideband (UWB) Internet of Things (IoT) sensors often exhibits inherent inaccuracies and susceptibility to noise and interference.

\cite{jiang_uwb_2020} introduced a novel methodology for data preprocessing and denoising in their seminal work. Moreover, they advocated for the utilization of sophisticated unsupervised machine learning algorithms, including Support Vector Machines (SVM), Convolutional Neural Networks (CNN), and Multilayer Perceptrons (MLP), for modeling the intricate dynamics of the acquired data.

Their pioneering approach not only addresses the challenges associated with noisy UWB IoT sensor data but also underscores the efficacy of employing advanced machine learning techniques for insightful data analysis and interpretation.

% An approach to calculate distance, as introduced by \cite{che_feature-based_2022}, involves leveraging Time-Of-Arrival (TOA) and Trilateration methodologies. However, due to the absence of detailed anchorpoint information, the Trilateration approach could not be executed. Instead, a modified formula was employed:


\begin{equation}
\text{Total Distance} = \sum_{i=1}^{n} |CIR_i| \cdot c
\end{equation}

where:

* $CIR_i$ represents the Channel Impulse Response for the $i$-th anchor point.
* $c$ is the speed of light in a vacuum, approximately $2.99792458 \times 10^8 \text{ m/s}$. We can use a constant value here for simplicity, assuming the context focuses on light propagation.

This formula facilitates distance estimation based on the cumulative Channel Impulse Response and the speed of light in nanoseconds. However, it's noteworthy that this derived feature is not utilized as part of the data mining process.



\subsection{Objective}\label{objective}

The primary aim of this assignment is to develop a model capable of discerning whether a given set of Channel Impulse Response (CIR) measurements corresponds to Line-of-Sight (LOS) or Non-Line-of-Sight (NLOS) scenarios. This entails the comprehensive execution of the three-dimensional process, encompassing Data Preprocessing, Data Mining, and Data Visualization. By diligently executing each phase of this process, the objective is to achieve a robust and insightful understanding of the dataset, culminating in the successful training of a model capable of accurate classification.


\section{Data Preprocessing}\label{data_preprocessing}

This section encompasses various preparatory procedures aimed at optimizing the data for subsequent analysis.

% \begin{description}[style=nextline]
%     \item[Feature Extraction:] Identification and extraction of pertinent features from the dataset.
%     \item[Feature Derivation:] Derivation of new features from existing ones to enhance predictive power.
%     \item[Feature Reduction:] Reduction of feature dimensionality to mitigate computational complexity.
%     \item[De-Noise Functions:] Application of functions to remove noise and enhance data quality.
%     \item[Justifications of Processes:] Explanations substantiating the rationale behind each preprocessing step.
% \end{description}

\subsection{Feature Extraction}\label{feature_extraction}


\subsection{Feature Derivation}\label{feature_derivation}

This section delineates the derivation of essential features from the Decawave Ultra-Wideband (UWB) Module datasheet, crucial for subsequent analysis.

\subsubsection{First Path Power Level}\label{first_path_power_level}

The First Path Power Level represents the strength of the primary signal path in the received Channel Impulse Response (CIR). It is calculated using the following equation:

\begin{equation}
  \text{FPPL} = 10 \cdot \log_{10} \left( \frac{A_1^2 + A_2^2 + A_3^2}{P_{acc}} \right) - \sigma_n
\end{equation}

where:

* $A_i$ (Current variable name: $FP\_AMPi$): Amplitude of the $i^{th}$ peak in the CIR ($i = 1, 2, 3$)
* $P_{acc}$ (Current variable name: $RXPACC$): Receiver path accumulation length
* $\sigma_n$ (Current variable name: $STDEV\_NOISE$): Standard deviation of the noise (typically 64)

\subsubsection{RX Level}\label{rx_level}

The RX Level quantifies the received signal strength relative to the receiver sensitivity threshold. It is computed as:

\begin{equation}
  \text{RX\_Level} =
  \begin{cases}
    0 & \text{if } \frac{P_{cir} \cdot 2^{17}}{P_{acc}} = 0 \\
    10 \cdot \log_{10} \left( \frac{P_{cir} \cdot 2^{17}}{P_{acc}} \right) - PRFR & \text{otherwise}
  \end{cases}
\end{equation}

where:

* $P_{cir}$ (Current variable name: $CIR\_PWR$): Power of the received Channel Impulse Response
* $PRFR$ (Current variable name unchanged): Power Range Finder Ratio

The median operation is employed to handle instances where the initial expression for RX Level yields a zero value, thus preventing undefined results.

\subsubsection{Signal-to-Noise Ratio (SNR)}\label{snr}

The Signal-to-Noise Ratio (SNR) is a metric used to quantify the quality of the received signal relative to the noise level. It is computed as:

\begin{equation}
  \text{SNR} = \frac{P_{cir}}{\sigma_n}
\end{equation}

where:

* $P_{cir}$ (Current variable name unchanged): Power of the received Channel Impulse Response
* $\sigma_n$ (Current variable name unchanged): Standard deviation of the noise

The SNR provides valuable insight into the reliability of the received signal amidst background noise. A visual representation of the SNR calculated is shown at Figure \ref{fig:snr}

\subsection{Feature Reduction}\label{feature_reduction}

\subsection{De-Noise Functions}\label{de_noise_Functions}


% Probably should just put diagrams and charts in data Visualization instead of here
% Just put accuracy and justification?
\section{Data Mining}\label{data_mining}

In this section, various data mining techniques are employed to extract meaningful insights from the preprocessed data.

% \begin{description}[style=nextline]
%     \item[Convolution Neural Network (CNN):] Detailed exposition of CNN model architecture and corresponding outcomes.
%     \item[Multilayer Perceptron (MLP):] Elucidation of MLP model structure and ensuing results.
%     \item[Comparison Between CNN and MLP:] Comparative analysis of CNN and MLP, along with justifications for the choice of each.
%     \item[Supervised Machine Learning Algorithms:] Discussion on the non-utilization of supervised algorithms and reasons thereof.
%     \item[Unsupervised Machine Learning Algorithms:] Explanation on the preference for CNN and MLP over unsupervised algorithms.
% \end{description}

\subsection{Convolution Neural Network (CNN)}\label{cnn} 

Model Creation: A Sequential model is created using Keras. This model is composed of the following layers: 
Conv1D layers: These are convolutional layers that will convolve the input data with a set of learnable filters, each producing one feature map in the output. The kernel size is set to 3, and the activation function used is ReLU (Rectified Linear Unit).  
MaxPooling1D layers: These layers are used to down-sample the input along its spatial dimensions (height and width). The pool size is set to 2.  
Dense layers: These are fully connected layers. The first Dense layer has 64 units and uses the ReLU activation function. The second Dense layer has a number of units equal to the number of classes and uses the softmax activation function to output a probability distribution over the classes.  
Model Compilation: The model is compiled with the Adam optimizer, categorical cross-entropy loss function, and accuracy as the evaluation metric.  
Model Training: The model is trained on the training data for 10 epochs with a batch size of 32. The validation data is set to the testing set.  
Model Evaluation: The model's performance is evaluated on the testing set and the accuracy is printed.  

The mathematical concept behind the Convolutional layer (Conv1D) is the convolution operation, which is a mathematical operation on two functions that produces a third function. In the context of a CNN, the two functions are the input data and the kernel or filter. The convolution operation involves sliding the kernel across the input data and computing the dot product at each position.

The mathematical formula for the convolution operation is:  $$ (f * g)(t) = \int_{-\infty}^{\infty} f(\tau)g(t - \tau) d\tau $$  Where:  
$f$ and $g$ are the input data and kernel respectively
$t$ is the position of the kernel
$\tau$ is a dummy integration variable
In the context of a CNN, the integral is replaced by a sum over the discrete spatial dimensions (height and width) of the input data and kernel.


% todo(ben): add info about how model is being trained %
\subsection{Multilayer Perceptron (MLP)}\label{mlp}                                                                                                         
Another approach involved training a Multilayer Perceptron (MLP) model using TensorFlow and Keras in Python. The decision to employ a Multilayer Perceptron (MLP) model for NLOS/LOS classification in this project hinges on its strengths in handling complex, non-linear relationships within the dataset. Unlike simpler models, MLPs boast a layered structure with each layer fully connected to the next. This intricate architecture empowers them to unearth intricate patterns in the data and translate those patterns into accurate predictions. This capability is particularly valuable for NLOS/LOS classification, where signal characteristics can exhibit significant variations due to environmental factors.

Beyond their prowess in handling non-linearity, MLPs offer a compelling advantage in terms of data versatility. They excel at processing a wide range of data types, including both numerical and categorical features. This characteristic makes them well-suited for NLOS/LOS classification tasks, where datasets often incorporate a mix of these data types. Furthermore, MLPs are inherently scalable. By adjusting the number of neurons and layers within the network, we can tailor the model's complexity to effectively capture the intricacies of the specific dataset at hand. This level of control allows us to optimize the model for the specific classification problem.

The training logs reveal the model's progression over 20 epochs. The initial accuracy of around 51.91\% in the first epoch steadily improves, reaching approximately 84.53\% by the final epoch. Similarly, the validation accuracy starts at 59.64\% and climbs to 83.93\%, indicating that the model generalizes well to unseen data. 

% Some figures from training %
\begin{figure}[H] 
	\centering
	\includegraphics[width=0.50\textwidth]{Mlp_training_and_accuracy_plot}
	\caption{MLP training and test accuracy plot}\label{fig:frequency_graph}
\end{figure}

A thorough analysis of the results reveals that the model maintains an accuracy of around 85\% throughout the epochs, indicating strong performance on the training data. In contrast, the test accuracy, though slightly lower than the training accuracy, remains stable around 80\% across epochs, suggesting reasonable generalization to unseen data. The observed gap between the training and test accuracy indicates potential overfitting, a common phenomenon where a model performs well on training data but struggles with unseen data.

\begin{figure}[H] 
	\centering
	\includegraphics[width=0.50\textwidth]{Mlp_training_and_validation_loss_plot}
	\caption{MLP training and validation loss plot}\label{fig:frequency_graph}
\end{figure}

Additionally, the training and validation loss over time plot for this model shows a promising trend. It suggests that the model is learning effectively and avoiding overfitting. The training loss appears to be steadily decreasing over the epochs, indicating that the model is continually improving its ability to fit the training data. Similarly, the validation loss also shows a decreasing trend, although it fluctuates slightly more than the training loss. Overall, the validation loss follows a similar pattern to the training loss, indicating that the model is generalizing well and not overfitting to the training data.

\begin{figure}[H] 
	\centering
	\includegraphics[width=0.50\textwidth]{Mlp_classification_report}
	\caption{Mlp training classification report}\label{fig:frequency_graph}
\end{figure}

% Overall performance of mlp %
The MLP model demonstrates strong performance on the test dataset, achieving an accuracy of 83.9\%. This accuracy reflects the model's ability to make correct predictions on unseen data. The precision, recall, and F1-score metrics provide a detailed assessment of the model's performance for each class. For class 0, the precision is 0.80, indicating that 80\% of the samples predicted as class 0 were correct, while the recall is 0.91, indicating that 91\% of the actual class 0 samples were identified correctly. Similarly, for class 1, the precision is 0.89 and the recall is 0.77. These metrics suggest that the model performs slightly better in identifying class 1 compared to class 0. The F1-scores for both classes are around 0.84, indicating a good balance between precision and recall. The classification report also includes macro and weighted average values, which provide a summarized view of the model's performance across both classes. The macro average values are 0.84 for all metrics, while the weighted average values are slightly higher at 0.85, reflecting a slight bias towards the slightly larger class (class 1). Overall, the classification report suggests that the MLP model generalizes well to unseen data and avoids overfitting, making it effective for the NLOS/LOS classification task.


\subsection{Comparison Between CNN and MLP}\label{cnn_vs_mlp}

% Decide whether are you using supervised or unsupervised learning? What algorithm should be preferred for your team? %
% Decide the split ratio of the training/test dataset such as 70:30 or 80:20? %
% Determine the classification, regression performance accuracy such as RMSE, confusion matrix etc? %
\subsection{Supervised Machine Learning Algorithms}\label{sml}

% TO WRITE %


% Decide whether are you using supervised or unsupervised learning? What algorithm should be preferred for your team? %
% Decide the split ratio of the training/test dataset such as 70:30 or 80:20? %
% Determine the classification, regression performance accuracy such as RMSE, confusion matrix etc? %
\subsection{Unsupervised Machine Learning Algorithms}\label{uml}


% TO WRITE %


% Plot the various performance indicators to illustrate the team choice and various result in data preprocessing & mining
\section{Data Visualization}\label{data_visualisation}

This section encompasses the graphical representation of data features and model architectures for enhanced comprehension.

% \begin{description}[style=nextline]
%     \item[Feature Visualization:] Visual depiction of both given and derived features for enhanced understanding.
%     \item[Convolution Neural Network:] Visual representation of CNN model architecture to facilitate interpretation.
%     \item[Multilayer Perceptron:] Visual depiction of MLP model architecture for improved insight into its workings.
% \end{description}

\subsection{Feature Visualization}\label{feature_visualization}

\subsubsection{Signal to Noise Raio}\label{snr}

\begin{figure}[H] 
	\centering
	\includegraphics[width=0.50\textwidth]{LOS_Frequency_Graph.png}
	\includegraphics[width=0.50\textwidth]{NLOS_Frequency_Graph.png}
	\caption{Frequency Graph of LOS and NLOS}\label{fig:frequency_graph}
\end{figure}

\subsubsection{Signal to Noise Raio}\label{snr}

\begin{figure}[H] % [H] forces the figure to be placed exactly where it appears in the text
	\centering % Horizontally center the figure
	\includegraphics[width=0.65\textwidth]{SNR} % Include the figure
	\caption{Signal to Noise Ratio}\label{fig:snr}
\end{figure}


\subsection{Convolution Neural Network}\label{cnn_visual}

\subsection{Multilayer Perceptron}\label{mlp_visual}


% \begin{center}
% 	\begin{tabular}{l r}
% 		Date Performed: & February 13, 2022 \\ % Date the experiment was performed
% 		Partners: & Cecilia \textsc{Smith} \\ % Partner names
% 		& Tajel \textsc{Khumalo} \\
% 		Instructor: & Professor \textsc{Rivera} % Instructor/supervisor
% 	\end{tabular}
% \end{center}

% If you need to include an abstract, uncomment the lines below
%\begin{abstract}
%	Abstract text
%\end{abstract}

%----------------------------------------------------------------------------------------
%	OBJECTIVE
%----------------------------------------------------------------------------------------

% \section{Objective}





% To determine the atomic weight of magnesium via its reaction with oxygen and to study the stoichiometry of the reaction (as defined in \ref{definitions}):

% \begin{center}
% 	\ce{2 Mg + O2 -> 2 MgO} % Chemical equations entered in \ce{} commands, see the mhchem package documentation for more information
% \end{center}

% If you have more than one objective, uncomment the below:
%\begin{description}
%	\item[First Objective] \hfill \\
%	Objective 1 text
%	\item[Second Objective] \hfill \\
%	Objective 2 text
%\end{description}

% \begin{description}
% 	\item[Stoichiometry] The relationship between the relative quantities of substances taking part in a reaction or forming a compound, typically a ratio of whole integers.
% 	\item[Atomic mass] The mass of an atom of a chemical element expressed in atomic mass units. It is approximately equivalent to the number of protons and neutrons in the atom (the mass number) or to the average number allowing for the relative abundances of different isotopes. 
% \end{description} 
 
%----------------------------------------------------------------------------------------
%	EXPERIMENTAL DATA
%----------------------------------------------------------------------------------------

% \section{Experimental Data}

% \begin{tabular}{l l}
% 	Mass of empty crucible & \SI{7.28}{\gram}\\ % Scientific/technical units are output using the \SI command, see the siunitx package documentation for more information on how to use this command
% 	Mass of crucible and magnesium before heating & \SI{8.59}{\gram}\\
% 	Mass of crucible and magnesium oxide after heating & \SI{9.46}{\gram}\\
% 	Balance used & \#4\\
% 	Magnesium from sample bottle & \#1
% \end{tabular}

%----------------------------------------------------------------------------------------
%	SAMPLE CALCULATION
%----------------------------------------------------------------------------------------

% \section{Sample Calculation}

% \begin{tabular}{ll}
% 	Mass of magnesium metal & = \SI{8.59}{\gram} - \SI{7.28}{\gram}\\
% 	& = \SI{1.31}{\gram}\\
% 	Mass of magnesium oxide & = \SI{9.46}{\gram} - \SI{7.28}{\gram}\\
% 	& = \SI{2.18}{\gram}\\
% 	Mass of oxygen & = \SI{2.18}{\gram} - \SI{1.31}{\gram}\\
% 	& = \SI{0.87}{\gram}
% \end{tabular}

% Because of this reaction, the required ratio is the atomic weight of magnesium: \SI{16.00}{\gram} of oxygen as experimental mass of Mg: experimental mass of oxygen or $\frac{x}{1.31} = \frac{16}{0.87}$ from which, $M_{\ce{Mg}} = 16.00 \times \frac{1.31}{0.87} = 24.1 = \SI{24}{\gram\per\mole}$ (to two significant figures).

%----------------------------------------------------------------------------------------
%	RESULTS AND CONCLUSIONS
%----------------------------------------------------------------------------------------

% \section{Results and Conclusions}

% The atomic weight of magnesium is concluded to be \SI{24}{\gram\per\mol}, as determined by the stoichiometry of its chemical combination with oxygen. This result is in agreement with the accepted value.

% \begin{figure}[H] % [H] forces the figure to be placed exactly where it appears in the text
% 	\centering % Horizontally center the figure
% 	\includegraphics[width=0.65\textwidth]{placeholder} % Include the figure
% 	\caption{Figure caption.}
% \end{figure}

%----------------------------------------------------------------------------------------
%	DISCUSSION
%----------------------------------------------------------------------------------------

% \section{Discussion of Experimental Uncertainty}

% The accepted value (periodic table) is \SI{24.3}{\gram\per\mole} \autocite{Smith:2022qr}. The percentage discrepancy between the accepted value and the result obtained here is 1.3\%. Because only a single measurement was made, it is not possible to calculate an estimated standard deviation (see \textcite{Smith:2021jd}).
 
% The most obvious source of experimental uncertainty is the limited precision of the balance. Other potential sources of experimental uncertainty are: the reaction might not be complete; if not enough time was allowed for total oxidation, less than complete oxidation of the magnesium might have, in part, reacted with nitrogen in the air (incorrect reaction); the magnesium oxide might have absorbed water from the air, and thus weigh ``too much." Because the result obtained is close to the accepted value it is possible that some of these experimental uncertainties have fortuitously cancelled one another.

%----------------------------------------------------------------------------------------
%	ANSWERS TO DEFINITIONS
%----------------------------------------------------------------------------------------

% \section{Answers to Definitions}

% \begin{enumerate}
% 	\item The \textit{atomic weight of an element} is the relative weight of one of its atoms compared to C-12 with a weight of 12.0000000$\ldots$, hydrogen with a weight of 1.008, to oxygen with a weight of 16.00. Atomic weight is also the average weight of all the atoms of that element as they occur in nature.
% 	\item The \textit{units of atomic weight} are two-fold, with an identical numerical value. They are g/mole of atoms (or just g/mol) or amu/atom.
% 	\item \textit{Percentage discrepancy} between an accepted (literature) value and an experimental value is:
% 		\begin{equation*}
% 			\frac{\mathrm{experimental\;result} - \mathrm{accepted\;result}}{\mathrm{accepted\;result}}
% 		\end{equation*}
% \end{enumerate}

%----------------------------------------------------------------------------------------
%	BIBLIOGRAPHY
%----------------------------------------------------------------------------------------

\printbibliography % Output the bibliography

%----------------------------------------------------------------------------------------

\end{document}
