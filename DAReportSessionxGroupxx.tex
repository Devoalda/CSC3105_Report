%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% University/School Laboratory Report
% LaTeX Template
% Version 4.0 (March 21, 2022)
%
% This template originates from:
% https://www.LaTeXTemplates.com
%
% Authors:
% Vel (vel@latextemplates.com)
% Linux and Unix Users Group at Virginia Tech Wiki
%
% License:
% CC BY-NC-SA 4.0 (https://creativecommons.org/licenses/by-nc-sa/4.0/)
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%----------------------------------------------------------------------------------------
%	PACKAGES AND DOCUMENT CONFIGURATIONS
%----------------------------------------------------------------------------------------

\documentclass[
	article, % Paper size, specify a4paper (A4) or letterpaper (US letter)
	11pt, % Default font size, specify 10pt, 11pt or 12pt
	draft, % Comment out before submission
]{CSUniSchoolLabReport}


\addbibresource{reference.bib} % Bibliography file (located in the same folder as the template)

\usepackage{enumitem}
\usepackage{hyperref}

%----------------------------------------------------------------------------------------
%	REPORT INFORMATION
%----------------------------------------------------------------------------------------

\title{CSC3105 Data Analytics Assignment} % Report title

\author{
        Woon Jun Wei \textit{2200624} \\
        Benjamin Loh Choon How \textit{2201590} \\
        Low Hong Sheng Jovian \textit{2203654}\\
        Wang Rongqi Richie \textit{2201942} \\
        Poon Xiang Yuan \textit{2200559} \\
    }

\date{\today} % Date of the report

%----------------------------------------------------------------------------------------

\begin{document}

\maketitle % Insert the title, author and date using the information specified above



% START of Jovian's draft for JW's verdict ): %
% DON TOUCH HERE unless u want to add on stuff %
\section{Background}\label{background}

\subsection{Emergence of IoT and Indoor Positioning Needs}\label{Emergence of IoT and Indoor Positioning Needs}
The advent of the Internet of Things (IoT) has revolutionized how we interact with our environment, giving rise to an increased demand for precise Indoor Positioning Systems (IPS). Applications range from pedestrian tracking to autonomous drones in logistics and social distancing protocols, all requiring reliable localization technologies.

\subsection{Limitations of GNSS in Indoor Environments}\label{Limitations of GNSS in Indoor Environments}
While the Global Navigation Satelite System (GNSS) has been a cornerstone for ourdoor localization, its effectiveness is drastically reduced indoors due to signal attentuation by obstacles like walls, making it unsuitable for indoor use.

\subsection{The Promise of UWB Technology}\label{The Promise of UWB Technology}
Ultra-Wideband (UWB) technology, with its short pulse duration, offers high temporal resolution, enabling high accuracy in IPS. Nonetheless, the accuracy of Ultra-wideband (UWB) systems is compromised under Non-Line-Of-Sight (NLOS) conditions, where signal obstructions or reflections occur, presenting a substantial hurdle due to the resulting deterioration in localization precision.

\subsection{Current NLOS Identification Methods}\label{Current NLOS Identification Methods}
The academic and industrial sectors have explored numerous methodologies to mitigate the NLOS issue in UWB systems. These range from non-feature-based approaches, leveraging contextual information, to feature-based methods that extract distinct waveform characteristics to identify NLOS conditions using maching learning (ML) techniques.

\subsection{Challenges and Limitations}\label{Challenges and Limitations}
Although ML has emerged as a promising solution for NLOS identification, existing feature-based approaches face challenges, particularly with imbalanced datasets where NLOS samples are scarce. This affects the robustness of the classifiers being trained.


\section{Introduction}\label{introduction}
In the field of signal processing and analytics, particularly within the context of Ultra-Wideband (UWB) Internet of Things (IoT) sensor technology, challenges such as data inaccuracies and vulnerability to noise and interference are prevalent. Recognizing the limitations inherent in conventional machine learning (ML) techniques, especially when dealing with imbalanced datasets typical of real-world applications, our project seeks to navigate these challenges by leveraging advanced ML algorithms and methodologies. Inspired by the innovative work of \cite{jiang_uwb_2020} on data preprocessing and denoising, as well as the feature-based distance calculation method proposed by \cite{che_feature-based_2022}, our initiative aims to enhance UWB localization precision through the differentiation of Line-of-Sight (LOS) and Non-Line-of-Sight (NLOS) conditions using a novel machine learning approach.

A pivotal element of our approach is the introduction of a proprietary distance formula designed to estimate distances more accurately within the UWB environment. This formula is expressed as:

\begin{equation}
\text{Total Distance} = \sum_{i=1}^{n} |CIR_i| \cdot c
\end{equation}

where:

\begin{itemize}
  \item $CIR_i$ represents the Channel Impulse Response for the $i$-th anchor point.
  \item $c$ is the speed of light in a vacuum, approximately $2.99792458 \times 10^8 \text{ m/s}$. We can use a constant value here for simplicity, assuming the context focuses on light propagation.
\end{itemize}

This formula facilitates distance estimation based on the cumulative Channel Impulse Response and the speed of light in nanoseconds. However, it is noteworthy that this derived feature is not utilized as part of the data mining process.


\section{Objective}\label{objective}
The cornerstone of this project is to forge a machine learning model adept at discerning between LOS and NLOS conditions based on Channel Impulse Response (CIR) measurements from UWB sensors. This ambition will be pursued through a holistic three-dimensional process comprising Data Preprocessing, Data Mining, and Data Visualization stages. By meticulously navigating through these phases, we aim to not only address the data imbalances and inaccuracies inherent in UWB sensor data but also to cultivate a comprehensive understanding of the dataset. The ultimate objective is to foster a robust classification model that maintains its efficacy across both LOS and NLOS scenarios, thereby elevating the accuracy and reliability of UWB-based Indoor Positioning Systems (IPS). Through this endeavor, we aspire to contribute significantly to the optimization of UWB localization technologies, ensuring their adaptability and effectiveness in diverse environmental conditions.


% % og intro, if above ok can combine / remove %
% \section{Introduction}\label{introduction}
% In the realm of signal processing and analytics, a diverse array of operations is available for data preprocessing, model training (data mining), and visualization. Notably, signal data acquired from Ultra-Wideband (UWB) Internet of Things (IoT) sensors often exhibits inherent inaccuracies and susceptibility to noise and interference.

% \cite{jiang_uwb_2020} introduced a novel methodology for data preprocessing and denoising in their seminal work. Moreover, they advocated for the utilization of sophisticated unsupervised machine learning algorithms, including Support Vector Machines (SVM), Convolutional Neural Networks (CNN), and Multilayer Perceptrons (MLP), for modeling the intricate dynamics of the acquired data.

% Their pioneering approach not only addresses the challenges associated with noisy UWB IoT sensor data but also underscores the efficacy of employing advanced machine learning techniques for insightful data analysis and interpretation.

% An approach to calculate distance, as introduced by \cite{che_feature-based_2022}, involves leveraging Time-Of-Arrival (TOA) and Trilateration methodologies. However, due to the absence of detailed anchorpoint information, the Trilateration approach could not be executed. Instead, a modified formula was employed:


% \begin{equation}
% \text{Total Distance} = \sum_{i=1}^{n} |CIR_i| \cdot c
% \end{equation}

% where:

% \begin{itemize}
%   \item $CIR_i$ represents the Channel Impulse Response for the $i$-th anchor point.
%   \item $c$ is the speed of light in a vacuum, approximately $2.99792458 \times 10^8 \text{ m/s}$. We can use a constant value here for simplicity, assuming the context focuses on light propagation.
% \end{itemize}

% This formula facilitates distance estimation based on the cumulative Channel Impulse Response and the speed of light in nanoseconds. However, it's noteworthy that this derived feature is not utilized as part of the data mining process.



% \subsection{Objective}\label{objective}

% The primary aim of this assignment is to develop a model capable of discerning whether a given set of Channel Impulse Response (CIR) measurements corresponds to Line-of-Sight (LOS) or Non-Line-of-Sight (NLOS) scenarios. This entails the comprehensive execution of the three-dimensional process, encompassing Data Preprocessing, Data Mining, and Data Visualization. By diligently executing each phase of this process, the objective is to achieve a robust and insightful understanding of the dataset, culminating in the successful training of a model capable of accurate classification.


\section{Data Preprocessing}\label{data_preprocessing}

This section encompasses various preparatory procedures aimed at optimizing the data for subsequent analysis.

\begin{description}[style=nextline]
    \item[Feature Extraction:] Identification and extraction of pertinent features from the dataset.
    \item[Feature Derivation:] Derivation of new features from existing ones to enhance predictive power.
    \item[Feature Reduction:] Reduction of feature dimensionality to mitigate computational complexity.
    \item[De-Noise Functions:] Application of functions to remove noise and enhance data quality.
    \item[Justifications of Processes:] Explanations substantiating the rationale behind each preprocessing step.
\end{description}

\subsection{Feature Extraction}\label{feature_extraction}


\subsection{Feature Derivation}\label{feature_derivation}

This section delineates the derivation of essential features from the Decawave Ultra-Wideband (UWB) Module datasheet, crucial for subsequent analysis. These derived features were used in the data mining phase to train the machine learning models.

\subsubsection{First Path Power Level}\label{first_path_power_level}

The First Path Power Level represents the strength of the primary signal path in the received Channel Impulse Response (CIR). It is calculated using the following equation:

\begin{equation}
  \text{First Path Power Level} = 10 \cdot \log_{10} \left( \frac{F_1^2 + F_2^2 + F_3^2}{N^2} \right) - A
\end{equation}

where:

\begin{itemize}
  \item $F_i$ (Current variable name: $FP\_AMPi$): Amplitude of the $i^{th}$ peak in the CIR ($i = 1, 2, 3$)
  \item $N$ (Current variable name: $RXPACC$): Receiver path accumulation length
  \item $A$ (Current variable name: $PRFR$):Pulse Repetition Frequncy Rate (typically 64)
\end{itemize}

\subsubsection{RX Level}\label{rx_level}

The RX Level quantifies the received signal strength relative to the receiver sensitivity threshold. It is computed as:

\begin{equation}
  \text{RX\_Level} =
  \begin{cases}
    0 & \text{if } \frac{P_{cir} \cdot 2^{17}}{N^2} = 0 \\
    10 \cdot \log_{10} \left( \frac{C \cdot 2^{17}}{N^2} \right) - A & \text{otherwise}
  \end{cases}
\end{equation}

where:

\begin{itemize}
  \item $C$ (Current variable name: $CIR\_PWR$): Power of the received Channel Impulse Response
  \item $N$ (Current variable name: $RXPACC$): Receiver path accumulation length
  \item $PRFR$ (Current variable name unchanged): Pulse Repetition Frequency Rate in MHz
\end{itemize}

The median operation is employed to handle instances where the initial expression for RX Level yields a zero value, thus preventing undefined results.

\subsubsection{Signal-to-Noise Ratio (SNR)}\label{snr}

The Signal-to-Noise Ratio (SNR) is a metric used to quantify the quality of the received signal relative to the noise level. It is computed as:

\begin{equation}
  \text{SNR} = \frac{P_{cir}}{\sigma_n}
\end{equation}

where:

\begin{itemize}
  \item $P_{cir}$ (Current variable name: $CIR\_PWR$): Power of the received Channel Impulse Response
  \item $\sigma_n$ (Current variable name $STDEV\_NOISE$): Standard deviation of the noise
\end{itemize}

The SNR provides valuable insight into the reliability of the received signal amidst background noise. A visual representation of the SNR calculated is shown at Figure \ref{fig:snr}

\subsection{Feature Reduction}\label{feature_reduction}

% Double check ALL formula, maybe cite or something idk
\subsection{De-Noise Functions}\label{de_noise_Functions}

In the paper by \cite{jiang_uwb_2020}, the authors proposed a novel denoising approach for UWB signals. They employed the Lucy-Richardson algorithm, a well-known deconvolution algorithm, to remove noise and enhance the quality of the received signal. The algorithm operates by iteratively estimating the original signal from the observed signal and the point spread function (PSF), which characterizes the blurring effect on the signal due to noise and other factors. The authors demonstrated the effectiveness of the Lucy-Richardson algorithm in denoising UWB signals and improving the accuracy of localization systems. The algorithm was shown to effectively remove noise and enhance the quality of the received signal, leading to improved localization accuracy and reliability.

However, they also suggested that the Wavelet Transformation approach is used more commonly in practice due to its simplicity and effectiveness. The Wavelet Transformation approach involves decomposing the signal into different frequency bands using wavelet functions, which allows for the removal of noise and the extraction of important features from the signal. The authors demonstrated the effectiveness of the Wavelet Transformation approach in denoising UWB signals and improving the accuracy of localization systems. The approach was shown to effectively remove noise and enhance the quality of the received signal, leading to improved localization accuracy and reliability.

In this section, we will explore the implementation of the Wavelet Transformation approach to denoise the UWB signals and enhance the quality of the received signal. We will also evaluate the effectiveness of the approach in improving the accuracy of the localization system and discuss its potential advantages and limitations.

\subsubsection{Wavelet Transformation}\label{wavelet_transformation}

The Wavelet Transformation approach involves decomposing the signal into different frequency bands using wavelet functions, which allows for removal of noise and extraction of important features from the signal. The approach has been widely used in signal processing and data analysis due to its simplicity and effectiveness. The Wavelet Transformation approach is particularly well-suited for denoising UWB signals, as it can effectively remove noise and enhance the quality of the received signal, leading to improved localization accuracy and reliability.

\textbf{Equation for Wavelet Transform:}

The Discrete Wavelet Transform (DWT) is commonly used for signal denoising. Here, the signal $x(t)$ is decomposed into a set of wavelet coefficients $W_f(a, \tau)$ at different scales $a$ and translations $\tau$:

\begin{equation}
W_f(a, \tau) = \int_{-\infty}^{\infty} x(t) \psi_{a, \tau}(t) dt
\end{equation}

where:

\begin{itemize}
  \item $W_f(a, \tau)$ represents wavelet coefficients
  \item $x(t)$ is the original signal
  \item $\psi_{a, \tau}(t)$ is the wavelet function (mother wavelet)
  \item $a$ is the scale parameter (controls wavelet's width)
  \item $\tau$ is the translation parameter (controls wavelet's position)
\end{itemize}

The denoising process involves applying a thresholding function to the wavelet coefficients, removing noise components and keeping the significant signal components. The reconstructed signal $x'(t)$ is obtained by integrating the denoised wavelet coefficients over all scales and translations:

The wavelet Daubechies wavelet is used to transform the LOS and NLOS signals. The transformed signals are then denoised using the Wavelet Transformation approach, which effectively removes noise and enhances the quality of the received signal. The denoised signals are then used as input to the machine learning models for training and testing.

\begin{equation}
x'(t) = \int_{-\infty}^{\infty} \sum_{a} W_f'(a, \tau) \psi_{a, \tau}(t) \frac{da d\tau}{a^2}
\end{equation}

where 

\begin{itemize}
  \item $W_f'(a, \tau)$: Denoised wavelet coefficients
  \item $\psi_{a, \tau}(t)$: Translated and scaled wavelet function
  \item $a$: Scale parameter
  \item $\tau$: Translation parameter
\end{itemize}

This approach is used to denoise the UWB CIR signals and enhance the quality of the received signal. The Wavelet Transformation approach has been shown to effectively remove noise and improve the accuracy of UWB localization systems. It is a simple and effective method for denoising UWB signals and enhancing the quality of the received signal, and it has the potential to improve the accuracy and reliability of UWB localization systems. It is used in the Data Mining phase during the model training process to improve the quality of the input data and enhance the performance of the machine learning models.

A visual of the frequency graph of the wavelet transformed LOS and NLOS signals is shown at Section \ref{frequency_graph_wavelet}.

\subsubsection{Lucy-Richardson Algorithm}

Given observed signal $I$ (cir\_values) and point spread function (PSF) $h$ (psf), the Richardson-Lucy algorithm aims to estimate the original signal $J$ through iterative refinement. The algorithm iteratively updates the estimate $J^{(k)}$ according to the following formula:

\begin{equation}
J^{(k+1)} = J^{(k)} \otimes \left( \frac{I}{(J^{(k)} \otimes h)} \right) \otimes h^T
\end{equation}

Where:
\begin{itemize}
    \item $J^{(k)}$ is the estimate of the original signal at iteration $k$.
    \item $\otimes$ denotes the convolution operation.
    \item $h^T$ represents the transpose of the PSF. 
\end{itemize}


The algorithm terminates after a specified number of iterations or upon reaching convergence criteria.

In the context of Python programming, this algorithm can be implemented using the following function:

\begin{verbatim}
def deconvolve_cir(cir_values, psf=None, iterations=50):
    # If no point spread function is provided, create a simple one
    if psf is None:
        psf = np.ones((5,)) / 5

    # Perform Richardson-Lucy deconvolution
    deconvolved_cir = restoration.richardson_lucy(
        cir_values, 
        psf, 
        num_iter=iterations
    )

    return deconvolved_cir
\end{verbatim}

This function takes circular (shifted) impulse response (CIR) values as input and performs Richardson-Lucy deconvolution. If no PSF is provided, a simple one is created. The number of iterations can also be specified. The result is the deconvolved CIR.

A visual of the frequency graph of the wavelet transformed LOS and NLOS signals is shown at Section \ref{frequency_graph_lr}. Notice that figure \ref{fig:frequency_graph_lr} shows a almost straight line across the graph, this might be due to the incorrect use of the function. Figure \ref{fig:frequency_graph_lr_scaled} shows a cleared, scaled image. This was not used in the Data mining phase due to its low variance as visualised in both figures.



% Probably should just put diagrams and charts in data Visualization instead of here
% Just put accuracy and justification?
\section{Data Mining}\label{data_mining}

In this section, various data mining techniques are employed to extract meaningful insights from the preprocessed data.

\begin{description}[style=nextline]
    \item[Convolution Neural Network (CNN):] Detailed exposition of CNN model architecture and corresponding outcomes.
    \item[Multilayer Perceptron (MLP):] Elucidation of MLP model structure and ensuing results.
    \item[Comparison Between CNN and MLP:] Comparative analysis of CNN and MLP, along with justifications for the choice of each.
    \item[Supervised Machine Learning Algorithms:] Discussion on the non-utilization of supervised algorithms and reasons thereof.
    \item[Unsupervised Machine Learning Algorithms:] Explanation on the preference for CNN and MLP over unsupervised algorithms.
\end{description}

\subsection{Convolution Neural Network (CNN)}\label{cnn}

Convolutional Neural Networks (CNNs) are a powerful class of deep learning models that have achieved remarkable success in various image recognition and signal processing tasks. Their ability to automatically learn spatial features from the input data makes them particularly well-suited for analyzing sequential data like UWB CIR signals. In this work, a CNN is employed to classify the received UWB signals based on the location information they contain.

\subsubsection{Model Architecture}

The CNN model architecture comprises Conv1D, BatchNormalization, Dropout, Flatten, and Dense layers:

\begin{itemize}
    \item \textbf{Conv1D Layers:} Two Conv1D layers with 64 and 32 filters respectively, kernel size of 3, ReLU activation, and L2 regularization for preventing overfitting.
    \item \textbf{BatchNormalization Layers:} Normalize activations to accelerate training and reduce overfitting.
    \item \textbf{Dropout Layers:} Implemented with a rate of 0.5 to prevent overfitting by randomly dropping input units.
    \item \textbf{Flatten Layer:} Flattens the input for transitioning between convolutional and dense layers.
    \item \textbf{Dense Layers:} Two dense layers with 64 units and softmax activation for multi-class classification.
\end{itemize}

\subsubsection{Model Compilation and Training}

\begin{itemize}
    \item \textbf{Optimizer:} Adam optimizer with a learning rate of 0.0001.
    \item \textbf{Loss Function:} Categorical cross-entropy for multi-class classification.
    \item \textbf{Metrics:} Accuracy is chosen as the evaluation metric.
    \item \textbf{Early Stopping:} Training halts if validation loss doesn't improve for 10 consecutive epochs.
    \item \textbf{Training Parameters:} Trained for 20 epochs with a batch size of 32.
\end{itemize}


\subsubsection{Convolution Operation}

The core mathematical concept underlying the Conv1D layers is the convolution operation. In simpler terms, convolution can be understood through an analogy:

\begin{quote}
 Imagine a policeman investigating a crime scene. The policeman (filter) systematically scans the scene (input data) searching for evidence (features). By sliding a magnifying glass (kernel) across different areas, the policeman extracts crucial details (feature maps) that contribute to solving the crime (classification task).
\end{quote}

Mathematically, the convolution operation is defined as:

\begin{equation}
(f * g)(t) = \int_{-\infty}^{\infty} f(\tau)g(t - \tau) d\tau
\end{equation}

where:

\begin{itemize}
  \item $f$ and $g$ are the input data and the kernel, respectively
  \item $*$ denotes the convolution operation
  \item $t$ is the position at which the convolution is computed
  \item $\tau$ is the integration variable
\end{itemize}

In the context of CNNs, the integral is replaced by a summation over the discrete spatial dimensions (width in the case of Conv1D layers) of the input data and the kernel. The convolution operation essentially computes the dot product between the filter and the input data at each position, capturing the presence and strength of the specific feature the filter is designed to detect.

\subsubsection{Justification for not Pre-reducing Features}

One might consider explicitly extracting features from the UWB CIR signals before feeding them into the CNN. However, this approach has limitations. Handcrafted features might not capture the most relevant information for the classification task. In contrast, CNNs excel at automatically learning these features directly from the raw data during the training process. This allows the model to identify the most discriminative features for achieving optimal


% todo(ben): add info about how model is being trained %
\subsection{Multilayer Perceptron (MLP)}\label{mlp}                                                                                 
The Multilayer Perceptron (MLP) model is a class of feedforward artificial neural network that consists of at least three layers of nodes: an input layer, a hidden layer, and an output layer. MLPs are known for their ability to handle complex, non-linear relationships within the dataset, making them suitable for a wide range of classification tasks. Unlike simpler models, MLPs boast a layered structure with each layer fully connected to the next. This intricate architecture empowers them to unearth intricate patterns in the data and translate those patterns into accurate predictions. This capability is particularly valuable for NLOS/LOS classification, where signal characteristics can exhibit significant variations due to environmental factors.

\subsubsection{Model Architecture}

The MLP model used in this project was constructed using TensorFlow and Keras. The model architecture includes several Dense layers, BatchNormalization layers, and Dropout layers:

\begin{itemize}
    \item \textbf{Dense layers:} The model utilizes a sequential stack of Dense layers with ReLU activation for non-linearity. The first layer has 64 units, followed by layers with 32 and 16 units respectively. The final layer has a single unit with a sigmoid activation function suitable for binary classification (NLOS vs. LOS).
    \item \textbf{Regularization Techniques:} L2 regularization with a weight decay of 0.001 is applied to each Dense layer to penalize large weights and encourage smoother decision boundaries, reducing overfitting.
    \item \textbf{Normalization and Dropout:} BatchNormalization layers are inserted after each Dense layer to improve training speed and stability by normalizing activations. Dropout layers with a rate of 0.5 are strategically placed after BatchNormalization to randomly drop a fraction of activations during training, further preventing overfitting by encouraging the model to learn robust features that are not dependent on specific input units.
\end{itemize}

\subsubsection{Model Compilation and Training}

\begin{itemize}
    \item \textbf{Data Preparation:} Prior to training, data undergoes feature scaling using a StandardScaler object to ensure all features have a zero mean and unit variance. This improves the convergence of the optimization algorithm.
    \item \textbf{Train-Test Split:} The data is split into training and testing sets with an 80:20 ratio, ensuring a representative sample for model evaluation.
    \item \textbf{Early Stopping:} An EarlyStopping callback monitors the validation loss during training. Training is halted if the validation loss fails to improve for 10 consecutive epochs, preventing overfitting.
    \item \textbf{Model Compilation:} The model is compiled using the Adam optimizer with a learning rate of 0.0001 and binary cross-entropy loss function, suitable for binary classification tasks. Accuracy is chosen as the primary evaluation metric.
    \item \textbf{Training Process:} The model is trained for 20 epochs with a batch size of 32. The training history is captured to visualize the learning process later.
\end{itemize}

In this model, the ReLU (Rectified Linear Unit) activation function is used in the hidden layers, introducing a threshold for activation. The sigmoid function is used in the output layer, as it maps the output between 0 and 1, suitable for binary classification tasks (NLOS vs. LOS).

The MLP model utilizes the Adam optimization algorithm, which dynamically adjusts the weights and biases throughout the training process. Adam optimizes these parameters to minimize the binary cross-entropy loss function, which quantifies the disparity between the model's predictions and the actual labels. Minimizing this loss function enables the model to enhance its ability to accurately classify the input data, making it a crucial component of the training process.tra

% % Some figures from training %
\begin{figure}[H] 
	\centering
	\includegraphics[width=0.50\textwidth]{Mlp_training_and_accuracy_plot}
	\caption{MLP training and test accuracy plot}\label{fig:mlp_training_and_accuracy_plot}
\end{figure}

A thorough analysis of the results reveals that the model maintains an accuracy of around 85\% throughout the epochs, indicating strong performance on the training data. In contrast, the test accuracy, though slightly lower than the training accuracy, remains stable around 80\% across epochs, suggesting reasonable generalization to unseen data. The observed gap between the training and test accuracy indicates potential overfitting, a common phenomenon where a model performs well on training data but struggles with unseen data.

\begin{figure}[H] 
	\centering
	\includegraphics[width=0.50\textwidth]{Mlp_training_and_validation_loss_plot}
	\caption{MLP training and validation loss plot}\label{fig:mlp_training_and_validation_loss_plot}
\end{figure}

Additionally, the training and validation loss over time plot for this model shows a promising trend. It suggests that the model is learning effectively and avoiding overfitting. The training loss appears to be steadily decreasing over the epochs, indicating that the model is continually improving its ability to fit the training data. Similarly, the validation loss also shows a decreasing trend, although it fluctuates slightly more than the training loss. Overall, the validation loss follows a similar pattern to the training loss, indicating that the model is generalizing well and not overfitting to the training data.

\begin{figure}[H] 
	\centering
	\includegraphics[width=0.50\textwidth]{Mlp_classification_report}
	\caption{Mlp training classification report}\label{fig:mlp_classification_report}
\end{figure}

% todo classification report Justification ^ %

\subsubsection{Multilayer Perceptron Operation}

The core mathematical concept underlying the Multilayer Perceptron (MLP) is the dot product operation, employed within the neurons of the Dense layers. In simpler terms, this can be understood through an analogy:

\begin{quote}
Imagine a robot deciding whether to go outside to play based on the weather. Each piece of information (input) about the temperature and weather condition (sunny or cloudy) is assigned a weight, representing its importance. The robot then calculates the total weighted sum of the inputs, adds a bias (its preference for certain weather conditions), and applies an activation function (decision rule) to determine if it should go outside (neuron activation).
\end{quote}

Mathematically, the output \(y\) of a single neuron is defined as:

\[
y = \phi \left( \sum_{i=1}^{n} w_i x_i + b \right)
\]

where:
\begin{itemize}
  \item \(w_i\) and \(x_i\) are the weights and input data, respectively
  \item \(n\) is the number of inputs to the neuron
  \item \(b\) is the bias
  \item \(\phi\) is the activation function
\end{itemize}

This operation essentially performs a weighted sum of the inputs, similar to linear regression. However, MLPs introduce non-linearity through activation functions, allowing them to learn more complex relationships between features and the output. This dot product operation can be visualized as a neuron taking a weighted sum of its input, adding a bias, and then passing the result through an activation function.

\subsection{Comparison Between CNN and MLP}\label{cnn_vs_mlp}

% Decide whether are you using supervised or unsupervised learning? What algorithm should be preferred for your team? %
% Decide the split ratio of the training/test dataset such as 70:30 or 80:20? %
% Determine the classification, regression performance accuracy such as RMSE, confusion matrix etc? %
\subsection{Supervised Machine Learning Algorithms}\label{sml}

% TO WRITE %


% Decide whether are you using supervised or unsupervised learning? What algorithm should be preferred for your team? %
% Decide the split ratio of the training/test dataset such as 70:30 or 80:20? %
% Determine the classification, regression performance accuracy such as RMSE, confusion matrix etc? %
\subsection{Unsupervised Machine Learning Algorithms}\label{uml}


% TO WRITE %


% Plot the various performance indicators to illustrate the team choice and various result in data preprocessing & mining
\section{Data Visualization}\label{data_visualisation}

This section encompasses the graphical representation of data features and model architectures for enhanced comprehension.

\begin{description}[style=nextline]
    \item[Feature Visualization:] Visual depiction of both given and derived features for enhanced understanding.
    \item[Convolution Neural Network:] Visual representation of CNN model architecture to facilitate interpretation.
    \item[Multilayer Perceptron:] Visual depiction of MLP model architecture for improved insight into its workings.
\end{description}

\subsection{Feature Visualization}\label{feature_visualization}

\subsubsection{Frequency Graph of LOS and NLOS}\label{frequency_graph}

\begin{figure}[H] 
	\centering
	\includegraphics[width=1\textwidth]{LOS_Frequency_Graph.png}
	\includegraphics[width=1\textwidth]{NLOS_Frequency_Graph.png}
	\caption{Frequency Graph of LOS and NLOS}\label{fig:frequency_graph}
\end{figure}

\subsubsection{Frequency Graph of Wavelet Transformed LOS and NLOS}\label{frequency_graph_wavelet}

\begin{figure}[H] 
  \centering
  \includegraphics[width=1\textwidth]{Wavelet_Denoised_LOS_Frequency_Graph.png}
  \includegraphics[width=1\textwidth]{Wavelet_Denoised_NLOS_Frequency_Graph.png}
  \caption{Frequency Graph of Wavelet Transformed LOS and NLOS}\label{fig:frequency_graph_wavelet}
\end{figure}

\subsubsection{Frequency Graph of Lucy-Richardson Transformation LOS and NLOS}\label{frequency_graph_lr}

\begin{figure}[H] 
  \centering
  \includegraphics[width=1\textwidth]{lr_denoise_LOS.png}
  \includegraphics[width=1\textwidth]{lr_denoise_NLOS.png}
  \caption{Frequency Graph of Lucy-Richardson(Unscaled) LOS and NLOS}\label{fig:frequency_graph_lr}
\end{figure}

\begin{figure}[H] 
  \centering
  \includegraphics[width=1\textwidth]{lr_denoise_LOS_Scaled.png}
  \includegraphics[width=1\textwidth]{lr_denoise_NLOS_Scaled.png}
  \caption{Frequency Graph of Lucy-Richardson(scaled) LOS and NLOS}\label{fig:frequency_graph_lr_scaled}
\end{figure}

\subsubsection{Signal to Noise Ratio}\label{sur_visual}

\begin{figure}[H] % [H] forces the figure to be placed exactly where it appears in the text
	\centering % Horizontally center the figure
	\includegraphics[width=1\textwidth]{SNR} % Include the figure
	\caption{Signal to Noise Ratio}\label{fig:snr}
\end{figure}


\subsection{Convolution Neural Network}\label{cnn_visual}

\subsection{Multilayer Perceptron}\label{mlp_visual}

\subsubsection{Weights and Biases Evaluation}\label{frequency_graph_wavelet}

\begin{figure}[H] 
  \centering
  \includegraphics[width=1\textwidth]{Mlp_dense_biases.png}
  \caption{Weights and Biases Evaluation}\label{fig:frequency_graph_wavelet}
\end{figure}

\begin{figure}[H] 
  \centering
  \includegraphics[width=1\textwidth]{Mlp_dense1_bias1.png}
  \caption{Weights and Biases Evaluation}\label{fig:frequency_graph_wavelet}
\end{figure}

\begin{figure}[H] 
  \centering
  \includegraphics[width=1\textwidth]{Mlp_dense2_bias2.png}
  \caption{Weights and Biases Evaluation}\label{fig:frequency_graph_wavelet}
\end{figure}

\begin{figure}[H] 
  \centering
  \includegraphics[width=1\textwidth]{Mlp_dense3_bias3.png}
  \caption{Weights and Biases Evaluation}\label{fig:frequency_graph_wavelet}
\end{figure}

\begin{figure}[H] 
  \centering
  \includegraphics[width=1\textwidth]{Mlp_confusion_matrix.png}
  \caption{Confusion Matrix Evaluation}\label{fig:frequency_graph_wavelet}
\end{figure}

\begin{figure}[H] 
  \centering
  \includegraphics[width=1\textwidth]{Mlp_ROC_Curve.png}
  \caption{ROC Curve Evaluation}\label{fig:frequency_graph_wavelet}
\end{figure}

% Might have use? %

% The training logs reveal the model's progression over 20 epochs. The initial accuracy of around 51.91\% in the first epoch steadily improves, reaching approximately 84.53\% by the final epoch. Similarly, the validation accuracy starts at 59.64\% and climbs to 83.93\%, indicating that the model generalizes well to unseen data. 

% % Overall performance of mlp %
% The MLP model demonstrates strong performance on the test dataset, achieving an accuracy of 83.9\%. This accuracy reflects the model's ability to make correct predictions on unseen data. The precision, recall, and F1-score metrics provide a detailed assessment of the model's performance for each class. For class 0, the precision is 0.80, indicating that 80\% of the samples predicted as class 0 were correct, while the recall is 0.91, indicating that 91\% of the actual class 0 samples were identified correctly. Similarly, for class 1, the precision is 0.89 and the recall is 0.77. These metrics suggest that the model performs slightly better in identifying class 1 compared to class 0. The F1-scores for both classes are around 0.84, indicating a good balance between precision and recall. The classification report also includes macro and weighted average values, which provide a summarized view of the model's performance across both classes. The macro average values are 0.84 for all metrics, while the weighted average values are slightly higher at 0.85, reflecting a slight bias towards the slightly larger class (class 1). Overall, the classification report suggests that the MLP model generalizes well to unseen data and avoids overfitting, making it effective for the NLOS/LOS classification task.

% \begin{center}
% 	\begin{tabular}{l r}
% 		Date Performed: & February 13, 2022 \\ % Date the experiment was performed
% 		Partners: & Cecilia \textsc{Smith} \\ % Partner names
% 		& Tajel \textsc{Khumalo} \\
% 		Instructor: & Professor \textsc{Rivera} % Instructor/supervisor
% 	\end{tabular}
% \end{center}

% If you need to include an abstract, uncomment the lines below
%\begin{abstract}
%	Abstract text
%\end{abstract}

%----------------------------------------------------------------------------------------
%	OBJECTIVE
%----------------------------------------------------------------------------------------

% \section{Objective}





% To determine the atomic weight of magnesium via its reaction with oxygen and to study the stoichiometry of the reaction (as defined in \ref{definitions}):

% \begin{center}
% 	\ce{2 Mg + O2 -> 2 MgO} % Chemical equations entered in \ce{} commands, see the mhchem package documentation for more information
% \end{center}

% If you have more than one objective, uncomment the below:
%\begin{description}
%	\item[First Objective] \hfill \\
%	Objective 1 text
%	\item[Second Objective] \hfill \\
%	Objective 2 text
%\end{description}

% \begin{description}
% 	\item[Stoichiometry] The relationship between the relative quantities of substances taking part in a reaction or forming a compound, typically a ratio of whole integers.
% 	\item[Atomic mass] The mass of an atom of a chemical element expressed in atomic mass units. It is approximately equivalent to the number of protons and neutrons in the atom (the mass number) or to the average number allowing for the relative abundances of different isotopes. 
% \end{description} 
 
%----------------------------------------------------------------------------------------
%	EXPERIMENTAL DATA
%----------------------------------------------------------------------------------------

% \section{Experimental Data}

% \begin{tabular}{l l}
% 	Mass of empty crucible & \SI{7.28}{\gram}\\ % Scientific/technical units are output using the \SI command, see the siunitx package documentation for more information on how to use this command
% 	Mass of crucible and magnesium before heating & \SI{8.59}{\gram}\\
% 	Mass of crucible and magnesium oxide after heating & \SI{9.46}{\gram}\\
% 	Balance used & \#4\\
% 	Magnesium from sample bottle & \#1
% \end{tabular}

%----------------------------------------------------------------------------------------
%	SAMPLE CALCULATION
%----------------------------------------------------------------------------------------

% \section{Sample Calculation}

% \begin{tabular}{ll}
% 	Mass of magnesium metal & = \SI{8.59}{\gram} - \SI{7.28}{\gram}\\
% 	& = \SI{1.31}{\gram}\\
% 	Mass of magnesium oxide & = \SI{9.46}{\gram} - \SI{7.28}{\gram}\\
% 	& = \SI{2.18}{\gram}\\
% 	Mass of oxygen & = \SI{2.18}{\gram} - \SI{1.31}{\gram}\\
% 	& = \SI{0.87}{\gram}
% \end{tabular}

% Because of this reaction, the required ratio is the atomic weight of magnesium: \SI{16.00}{\gram} of oxygen as experimental mass of Mg: experimental mass of oxygen or $\frac{x}{1.31} = \frac{16}{0.87}$ from which, $M_{\ce{Mg}} = 16.00 \times \frac{1.31}{0.87} = 24.1 = \SI{24}{\gram\per\mole}$ (to two significant figures).

%----------------------------------------------------------------------------------------
%	RESULTS AND CONCLUSIONS
%----------------------------------------------------------------------------------------

% \section{Results and Conclusions}

% The atomic weight of magnesium is concluded to be \SI{24}{\gram\per\mol}, as determined by the stoichiometry of its chemical combination with oxygen. This result is in agreement with the accepted value.

% \begin{figure}[H] % [H] forces the figure to be placed exactly where it appears in the text
% 	\centering % Horizontally center the figure
% 	\includegraphics[width=0.65\textwidth]{placeholder} % Include the figure
% 	\caption{Figure caption.}
% \end{figure}

%----------------------------------------------------------------------------------------
%	DISCUSSION
%----------------------------------------------------------------------------------------

% \section{Discussion of Experimental Uncertainty}

% The accepted value (periodic table) is \SI{24.3}{\gram\per\mole} \autocite{Smith:2022qr}. The percentage discrepancy between the accepted value and the result obtained here is 1.3\%. Because only a single measurement was made, it is not possible to calculate an estimated standard deviation (see \textcite{Smith:2021jd}).
 
% The most obvious source of experimental uncertainty is the limited precision of the balance. Other potential sources of experimental uncertainty are: the reaction might not be complete; if not enough time was allowed for total oxidation, less than complete oxidation of the magnesium might have, in part, reacted with nitrogen in the air (incorrect reaction); the magnesium oxide might have absorbed water from the air, and thus weigh ``too much." Because the result obtained is close to the accepted value it is possible that some of these experimental uncertainties have fortuitously cancelled one another.

%----------------------------------------------------------------------------------------
%	ANSWERS TO DEFINITIONS
%----------------------------------------------------------------------------------------

% \section{Answers to Definitions}

% \begin{enumerate}
% 	\item The \textit{atomic weight of an element} is the relative weight of one of its atoms compared to C-12 with a weight of 12.0000000$\ldots$, hydrogen with a weight of 1.008, to oxygen with a weight of 16.00. Atomic weight is also the average weight of all the atoms of that element as they occur in nature.
% 	\item The \textit{units of atomic weight} are two-fold, with an identical numerical value. They are g/mole of atoms (or just g/mol) or amu/atom.
% 	\item \textit{Percentage discrepancy} between an accepted (literature) value and an experimental value is:
% 		\begin{equation*}
% 			\frac{\mathrm{experimental\;result} - \mathrm{accepted\;result}}{\mathrm{accepted\;result}}
% 		\end{equation*}
% \end{enumerate}

%----------------------------------------------------------------------------------------
%	BIBLIOGRAPHY
%----------------------------------------------------------------------------------------

\printbibliography % Output the bibliography

%----------------------------------------------------------------------------------------

\end{document}
